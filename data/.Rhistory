install.packages(pkgs=c("CircStats", "deSolve", "coda", "deldir", "igraph", "RandomFields", "ks"))
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make.
Install <- TRUE
toInstall <- c("ggplot2", "ggmap", "plyr", "lme4", "rgl", "vegan", "scatterplot3d", "VGAM")
if(Install){
install.packages(toInstall,
dependencies = TRUE,
repos = "http://cran.us.r-project.org")
}
library(ggplot2)
library(ggmap)
library(plyr)
library(ggplot2)
MyData <- data.frame(X = rnorm(100), Y = rnorm(100))
p1     <- ggplot(MyData)
p1     <- p1 + geom_point(aes(x = X,y = Y))
p1     #This should produce a graph.
setwd("~/GitHub/IODS-project/data")
mat<-read.csv("student-mat.csv",header = T, sep = ";")
por<-read.csv("student-por.csv",header = T, sep = ";")
#check structure and dimensions of the data
str(mat)
str(por)
#in Rstudio I can see dimensions of the data from the environment window also
dim(mat)
dim(por)
##############################################################################################
#joining datasets
# access the dplyr library
library(dplyr)
# common columns to use as identifiers
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")
# join the two datasets by the selected identifiers
math_por <- inner_join(mat, por, by = join_by,suffix=c(".math",".por"))
#check structure
str(math_por)
#dimensions
dim(math_por)
#####################################################################################
#combining duplicated answers
# print out the column names of 'math_por'
colnames(math_por)
# create a new data frame with only the joined columns
alc <- select(math_por, one_of(join_by))
# the columns in the datasets which were not used for joining the data
notjoined_columns <- colnames(mat)[!colnames(mat) %in% join_by]
# print out the columns not used for joining
notjoined_columns
# for every column name not used for joining...
for(column_name in notjoined_columns) {
# select two columns from 'math_por' with the same original name
two_columns <- select(math_por, starts_with(column_name))
# select the first column vector of those two columns
first_column <- select(two_columns, 1)[[1]]
# if that first column vector is numeric...
if(is.numeric(first_column)) {
# take a rounded average of each row of the two columns and
# add the resulting vector to the alc data frame
alc[column_name] <- round(rowMeans(two_columns))
} else { # else if it's not numeric...
# add the first column vector to the alc data frame
alc[column_name] <- first_column
}
}
# glimpse at the new combined data
glimpse(alc)
# access the 'tidyverse' packages dplyr and ggplot2
library(dplyr); library(ggplot2)
# define a new column alc_use by combining weekday and weekend alcohol use
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
# access the 'tidyverse' packages dplyr and ggplot2
library(dplyr)
# define a new column alc_use by combining weekday and weekend alcohol use
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
# define a new column alc_use by combining weekday and weekend alcohol use
alc <- dplyr::mutate(alc, alc_use = (Dalc + Walc) / 2)
install.packages("dplyr")
# define a new column alc_use by combining weekday and weekend alcohol use
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
# access the 'tidyverse' packages dplyr and ggplot2
library(dplyr)
# define a new column alc_use by combining weekday and weekend alcohol use
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
View(alc)
# define a new logical column 'high_use' which is TRUE if alc_use is greater than 2.
alc <- mutate(alc, high_use = alc_use > 2)
#check that everything is correct
glimpse(alc)
#dimensions
dim(alc)
#save the data in csv
write.csv(alc,"alc.csv",row.names = F)
#data can be read in with read.csv-command and it has headers, T means TRUE.
learning2014<-read.csv("F:/kurssit/GitHub/IODS-project/data/learning2014.csv",header = T)
#data can be read in with read.csv-command and it has headers, T means TRUE.
learning2014<-read.csv("C:/GitHub/IODS-project/data/learning2014.csv",header = T)
#data can be read in with read.csv-command and it has headers, T means TRUE.
learning2014<-read.csv("C://GitHub/IODS-project/data/learning2014.csv",header = T)
#data can be read in with read.csv-command and it has headers, T means TRUE.
learning2014<-read.csv("C:/Users/Sirke Piirainen/Documents/GitHub/IODS-project/data/learning2014.csv",header = T)
alc<-read.csv("C:/Users/Sirke Piirainen/Documents/GitHub/IODS-project/data/learning2014.csv",header = T)
alc<-read.csv("C:/Users/Sirke Piirainen/Documents/GitHub/IODS-project/data/learning2014.csv",header = T)
#print the names of the columns
names(alc)
#read in the csv
alc<-read.csv("C:/Users/Sirke Piirainen/Documents/GitHub/IODS-project/data/alc.csv",header = T)
#print the names of the columns
names(alc)
choose<-c("famrel","absences","studytime","higher")
alc2<-select(alc,by=choose)
View(alc2)
choose<-c("high_use","famrel","absences","studytime","higher")
alc2<-select(alc,one_of(choose))
# create a plot matrix with ggpairs()
p <- ggpairs(alc2, mapping = aes(alpha=0.3), lower = list(combo = wrap("facethist", bins = 20)))
library(GGally)
# create a plot matrix with ggpairs()
p <- ggpairs(alc2, mapping = aes(alpha=0.3), lower = list(combo = wrap("facethist", bins = 20)))
# draw the plot
p
# create a plot matrix with ggpairs()
p <- ggpairs(alc2, mapping = aes(col=high_use,alpha=0.3), lower = list(combo = wrap("facethist", bins = 20)))
# draw the plot
p
boxplot(high_use,famrel)
# initialize plot with data and aesthetic mapping
p1 <- ggplot(alc2, aes(x = high_use, y = famrel,))
# initialize plot with data and aesthetic mapping
p1 <- ggplot(alc2, aes(x = high_use, y = famrel,)
# define the visualization type (points)
p2 <- p1 + geom_point()
# define the visualization type (points)
p2 <- p1 + geom_bar()
# draw the plot
p2
barplot(high_use, studytime)
gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free")+geom_bar()
library(tidyr); library(dplyr); library(ggplot2)
gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free")+geom_bar()
gather(alc2) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free")+geom_bar()
#draw a combined plot aswell
# initialize plot with data and aesthetic mapping
p1 <- ggplot(alc2, aes(x = high_use, y = famrel)
# define the visualization type (points)
p2 <- p1 + geom_bar()
#draw a combined plot aswell
# initialize plot with data and aesthetic mapping
p1 <- ggplot(alc2, aes(x = high_use, y = famrel))
# define the visualization type (points)
p2 <- p1 + geom_bar()
# draw the plot
p2
#draw some individual barplots
gather(alc2) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free")+geom_bar()
#draw some individual barplots
gather(alc2) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free")+geom_bar()
#draw some individual barplots
gather(alc2) %>% ggplot(aes(value),col=high_use) + facet_wrap("key", scales = "free")+geom_bar()
gather(alc2) %>% ggplot(aes(value),col=high_use) + facet_wrap("key", scales = "free")+geom_bar()
p1 <- ggplot(alc2, aes(x = high_use, y = famrel))
# define the visualization type (points)
p2 <- p1 + geom_bar()
# draw the plot
p2
#draw barplots of variables to study their distribution
gather(alc2) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free")+geom_bar()
dim(alc2$absences)
range(alc2$absences)
summary(alc2)
#summary of the data
summary(alc2)
#get some packages
library(tidyr); library(dplyr); library(ggplot2)
#draw barplots of variables to study their distribution
gather(alc2) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free")+geom_bar()
alc2$absences
library(GGally)
library(ggplot2)
# create a plot matrix with ggpairs()
p <- ggpairs(alc2, mapping = aes(col=high_use,alpha=0.3), lower = list(combo = wrap("facethist", bins = 20)))
# draw the plot
p
#fit a logistic regression model
m <- glm(high_use ~ famrec + absences+studytime+higher, data = alc2, family = "binomial")
#fit a logistic regression model
m <- glm(high_use ~ famrel + absences+studytime+higher, data = alc2, family = "binomial")
#plot a summary table
summary(m)
#print the coefficients of the model
coef(m)
#count odd ratios
OR <- coef(m) %>% exp
# compute confidence intervals (CI)
CI<-confint(m)%>%exp
# print out the odds ratios with their confidence intervals
cbind(OR, CI)
#fit a logistic regression model
m <- glm(high_use ~ famrel + absences+studytime+higher-1, data = alc2, family = "binomial")
#plot a summary table
summary(m)
#count odd ratios
OR <- coef(m) %>% exp
# compute confidence intervals (CI)
CI<-confint(m)%>%exp
# print out the odds ratios with their confidence intervals
cbind(OR, CI)
my.mod1 <- glm(high_use ~ famrel + absences+studytime+higher-1, data = alc2, family = "binomial") # with rank
my.mod2 <- glm(high_use ~ famrel + absences+studytime-1, data = alc2, family = "binomial") # without rank
anova(my.mod1, my.mod2, test="LRT")
#summary table of the new model
summary(my.mod2)
#the new model again
m2 <- glm(high_use ~ famrel + absences+studytime-1, data = alc2, family = "binomial")
#count odd ratios
OR <- coef(m2) %>% exp
# compute confidence intervals (CI)
CI<-confint(m2)%>%exp
# print out the odds ratios with their confidence intervals
cbind(OR, CI)
#the new model again
m2 <- glm(high_use ~ famrel + absences+studytime-1, data = alc2, family = "binomial")
#summary table of the new model
summary(my.mod2)
#the new model again
m2 <- glm(high_use ~ famrel + absences+studytime, data = alc2, family = "binomial")
#summary table of the new model
summary(my.mod2)
#summary table of the new model
summary(m2)
m3<-glm(formula = high_use ~ absences + studytime, family = "binomial",
data = alc2)
summary(m3)
#count odd ratios
OR <- coef(m3) %>% exp
# compute confidence intervals (CI)
CI<-confint(m3)%>%exp
# print out the odds ratios with their confidence intervals
cbind(OR, CI)
# predict() the probability of high_use
probabilities <- predict(m3, type = "response")
# add the predicted probabilities to 'alc'
alc2 <- mutate(alc2, probability = probabilities)
# use the probabilities to make a prediction of high_use
alc2 <- mutate(alc2, prediction = probability>0.5)
# see the last ten original classes, predicted probabilities, and class predictions
select(alc2, studytime, absences, high_use, probability, prediction) %>% tail(10)
# tabulate the target variable versus the predictions
table(high_use = alc2$high_use, prediction = alc2$prediction)
g <- ggplot(alc2, aes(x = probability, y = high_use,col=prediction))
# define the geom as points and draw the plot
g+geom_point()
# tabulate the target variable versus the predictions
table(high_use = alc2$high_use, prediction = alc2$prediction)%>%prop.table()%>%addmargins()
# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)%>%prop.table()%>%addmargins()
table(high_use = alc2$high_use, prediction = alc2$prediction)%>%prop.table()%>%addmargins()
# use the probabilities to make a prediction of high_use
alc2 <- mutate(alc2, prediction = probability>0.5)
# see the last ten original classes, predicted probabilities, and class predictions
select(alc2, studytime, absences, high_use, probability, prediction) %>% tail(10)
# tabulate the target variable versus the predictions
table(high_use = alc2$high_use, prediction = alc2$prediction)
# tabulate the target variable versus the predictions
table(high_use = alc2$high_use, prediction = alc2$prediction)%>%prop.table()%>%addmargins()
# tabulate the target variable versus the predictions
table(high_use = alc2$high_use, prediction = alc2$prediction)
# tabulate the target variable versus the predictions
table(high_use = alc2$high_use, prediction = alc2$prediction)%>%prop.table()%>%addmargins()
# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
n_wrong <- abs(class - prob) > 0.5
mean(n_wrong)
}
# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc2$high_use, prob = alc2$probability)
#get some packages
library(tidyr); library(dplyr); library(ggplot2)
#select only the data that I am interested in
choose<-c("high_use","famrel","absences","studytime","higher")
alc2<-select(alc,one_of(choose))
