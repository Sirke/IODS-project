summarize,
CTL = seq(min(CTL), max(CTL), length = 25))
MyData
P <- predict(M3, newdata = MyData, se = TRUE, type = "link")
#Add fitted values and confidence bands
MyData$mu    <- exp(P$fit)  #Fitted values
MyData$selow <- exp(P$fit - 2 * P$se.fit)  #lower bound
MyData$seup  <- exp(P$fit + 2 * P$se.fit)  #upper bound
head(MyData)
p <- ggplot()
p <- p + geom_point(data = Crayfish2,
aes(y = Weight, x = CTL),
shape = 16,
size = 3)
p <- p + xlab("Cephalotorax Length (mm)") + ylab("Weight in grams")
p <- p + theme(text = element_text(size=15)) + theme_bw()
p <- p + geom_line(data = MyData,
aes(x = CTL, y = mu),
colour = "black")
p <- p + geom_ribbon(data = MyData,
aes(x = CTL,
ymax = seup,
ymin = selow ),
alpha = 0.5)
p <- p + facet_grid(. ~ Sex, scales = "fixed")
p
M4 <- glm(Weight ~ LOGCTL + factor(Sex),
family = Gamma(link= "log"),
data = Crayfish2)
summary(M4)
#Homogeneity
E4 <- resid(M4, type = "pearson")
F4 <- fitted(M4)
plot(x = F4,
y = E4,
xlab = "Fitted values",
ylab = "Residuals",
main = "Homogeneity?")
abline(h = 0, v = 0, lty = 2)
#Independence due to model misfit
#Plot residuals versus covariates
plot(x = Crayfish2$CTL,
y = E4)
abline(h = 0,
lty = 2)
#Model interpretation
summary(M4)
#Model interpretation
summary(M4)
#Scale parameter:
r <- 1 / summary(M4)$dispersion
r
###########################################################
#Sketch fitted values
MyData <- ddply(Crayfish2,
.(Sex),
summarize,
LOGCTL = seq(min(LOGCTL), max(LOGCTL), length = 25))
MyData
P <- predict(M4, newdata = MyData, se = TRUE, type = "link")
#Add fitted values and confidence bands
MyData$mu    <- exp(P$fit)  #Fitted values
MyData$selow <- exp(P$fit - 2 * P$se.fit)  #lower bound
MyData$seup  <- exp(P$fit + 2 * P$se.fit)  #upper bound
head(MyData)
p <- ggplot()
p <- p + geom_point(data = Crayfish2,
aes(y = Weight, x = LOGCTL),
shape = 16,
size = 3)
p <- p + xlab("Cephalotorax Length (mm)") + ylab("Weight in grams")
p <- p + theme(text = element_text(size=15)) + theme_bw()
p <- p + geom_line(data = MyData,
aes(x = LOGCTL, y = mu),
colour = "black")
p <- p + geom_ribbon(data = MyData,
aes(x = LOGCTL,
ymax = seup,
ymin = selow ),
alpha = 0.5)
p <- p + facet_grid(. ~ Sex, scales = "fixed")
p
M2 <- glm(LOGWeight ~ LOGCTL + factor(Sex),
data = Crayfish2,
family = gaussian)
M4 <- glm(Weight ~ LOGCTL + factor(Sex),
family = Gamma(link= "log"),
data = Crayfish2)
AIC(M2, M4)  # You need to ensure that the AIC function calculates the
# full likelihood, and that it does not drop constants.
# full likelihood, and that it does not drop constants.
# Faraway (2006) shows that this is indeed the case, which
# full likelihood, and that it does not drop constants.
# Faraway (2006) shows that this is indeed the case, which
# makes comparing AICs tricky. Try to program your own
#I suggest you base you assessment on residuals.
#I suggest you base you assessment on residuals.
#I suggest you base you assessment on residuals.
#I suggest you base you assessment on residuals.
#I suggest you base you assessment on residuals.
#I suggest you base you assessment on residuals.
#I suggest you base you assessment on residuals.
library(lattice)
library(ggplot2)
source("HighstatLibV10.R")
########################################################################
#Dump the rubbish and keep the relevant variables
CTT2 <- data.frame(Window        = CTT$window.duration,
Stress        = CTT$stress.type,
Fertilization = CTT$fertilization,
Competition   = CTT$competition,
Biomass       = CTT$Triadica.aboveground.biomass)
str(CTT2)
CTT <- read.csv(file = "CTT_V2.csv",
header = TRUE)
names(CTT)
str(CTT)
library(lattice)
library(ggplot2)
source("HighstatLibV10.R")
########################################################################
#Dump the rubbish and keep the relevant variables
CTT2 <- data.frame(Window        = CTT$window.duration,
Stress        = CTT$stress.type,
Fertilization = CTT$fertilization,
Competition   = CTT$competition,
Biomass       = CTT$Triadica.aboveground.biomass)
str(CTT2)
# A. Missing values?
colSums(is.na(CTT2))
# B. Outliers
table(CTT2$Window)
table(CTT2$Stress)
table(CTT2$Fertilization)
table(CTT2$Competition)
# C. Relationship
boxplot(Biomass ~ Window, data = CTT2)
# C. Relationship
boxplot(Biomass ~ Window, data = CTT2)
boxplot(Biomass ~ Stress, data = CTT2)
boxplot(Biomass ~ Fertilization, data = CTT2)
boxplot(Biomass ~ Stress, data = CTT2)
boxplot(Biomass ~ Fertilization, data = CTT2)
boxplot(Biomass ~ Competition, data = CTT2)
plot(x = CTT2$Window,
y = CTT2$Biomass)
# D. Relationships
MyVar <- c("Biomass")
Mydotplot(CTT2[, MyVar])
par(mar = c(5,5,2,2), cex.lab = 1.5)
plot(y = 1:nrow(CTT2),
x = CTT2$Biomass,
xlab = "Range of the variable",
ylab = "Order of the data",
pch = 16)
# E. Check the percentage of zeros
sum(CTT2$Biomass == 0) / nrow(CTT2)  #That is high
sum(CTT2$Biomass > 0)                #Important to know this!
# Start crazy and include all 3 way interactions?
# They did something like that in the paper.
M1 <- lm(Biomass ~ (Window + Stress + Fertilization + Competition)^3,
data = CTT2)
summary(M1)
drop1(M1, test = "F")
# Let's do model validation first...just in case
# there is something that stops us from working
# with this model altogether.
E1 <- resid(M1)
F1 <- fitted(M1)
# Plot resudals vs fitted values
par(mar = c(5,5,2,2), cex.lab = 1.5)
plot(x = F1,
y = E1,
xlab = "Fitted values",
ylab = "Residuals")
abline(h = 0, lty = 2)
abline(v = 0, lty = 2)
# Plot the residuals vs each covariate in the model
CTT2$E1 <- resid(M1)
Myxyplot(CTT2, "Window", "E1")
# Should we have used Window as a factor?
boxplot(E1 ~ Window, data = CTT2)
drop1(lm(E1 ~ factor(Window), data = CTT2), test = "F")
# Standardize the covariate and convert Biomass
# into absence-presence data
CTT2$Window.std <- MyStd(CTT2$Window)
CTT2$Biomass.01 <- CTT2$Biomass
CTT2$Biomass.01[CTT2$Biomass > 0] <- 1
# Apply Bernoulli GLM
M2 <- glm(Biomass.01 ~ Window.std + Fertilization + Stress + Competition,
data = CTT2,
family = binomial)
summary(M2)
drop1(M2, test = "Chi")
step(M2)
AIC(M2)
# First plot the frequentist model M2
MyData <- expand.grid(Window.std = seq(-1.41, 1.41, length = 100),
Fertilization = levels(CTT2$Fertilization),
Competition = levels(CTT2$Competition),
Stress = levels(CTT2$Stress))
P2          <- predict(M2, newdata = MyData, se = TRUE, type = "link")
MyData$Pi   <- exp(P2$fit) / (1 + exp(P2$fit))
MyData$SeUp <- exp(P2$fit + 1.96*P2$se.fit) / (1 + exp(P2$fit + 1.96*P2$se.fit))
MyData$SeLo <- exp(P2$fit - 1.96*P2$se.fit) / (1 + exp(P2$fit - 1.96*P2$se.fit))
head(MyData)
MyData$Window <- MyData$Window.std * sd(CTT2$Window) + mean(CTT2$Window)
p <- ggplot()
p <- p + geom_point(data = CTT2,
aes(y = Biomass.01, x = Window),
shape = 1,
size = 1)
p <- p + geom_jitter(data = CTT2,
aes(y = Biomass.01, x = Window),
position = position_jitter(height = .01,
width = 0.5))
p <- p + xlab("Window") + ylab("Probability of biomass > 0")
p <- p + theme(text = element_text(size=15))
p <- p + ylim(c(0,1))
p <- p + geom_line(data = MyData,
aes(x = Window,
y = Pi,
group = Competition,
colour = Competition,
fill = Competition))
p <- p + geom_ribbon(data = MyData,
aes(x = Window,
ymax = SeUp,
ymin = SeLo,
group = Competition,
colour = Competition,
fill = Competition),
alpha = 0.2)
p <- p + facet_grid(Fertilization ~ Stress, scales = "fixed")
p
#Get the positive data and apply gamma GLM
CTT2.pos <- CTT2[CTT2$Biomass>0,]
M3 <- glm(Biomass ~ Window.std + Fertilization + Competition + Stress,
data = CTT2.pos,
family = Gamma(link ="log"))
summary(M3)
resid(M3, type = "pearson")
library(MASS)
MyShape <- gamma.shape(M3)
MyShape  #This is the frequentist r
MyData <- expand.grid(Window.std    = seq(-1.41, 1.41, length = 100),
Fertilization = levels(CTT2$Fertilization),
Competition   = levels(CTT2$Competition),
Stress        = levels(CTT2$Stress))
MyData$Window <- MyData$Window.std * sd(CTT2$Window) + mean(CTT2$Window)
X <- model.matrix(~ Window.std + Fertilization + Competition + Stress,
data = MyData)
beta      <- coef(M3)
eta       <- X %*% beta
se        <- sqrt(diag(X %*% vcov(M3) %*% t(X)))
MyData$mu <- exp(eta)
MyData$up <- exp(eta + 1.96 * se)
MyData$lo <- exp(eta - 1.96 * se)
p <- ggplot()
p <- p + geom_jitter(data = CTT2.pos,
aes(y = Biomass, x = Window),
position = position_jitter(height = .1, width = 0.5))
p <- p + xlab("Window") + ylab("Biomass")
p <- p + theme(text = element_text(size=15))
p <- p + geom_line(data = MyData,
aes(x = Window,
y = mu,
group = Competition,
colour = Competition,
fill = Competition))
p <- p + geom_ribbon(data = MyData,
aes(x = Window,
ymax = up,
ymin = lo,
group = Competition,
colour = Competition,
fill = Competition),
alpha = 0.2)
p <- p + facet_grid(Fertilization ~ Stress, scales = "fixed")
p
# Step 1:
CTT2$Biomass01 <- as.numeric(CTT2$Biomass > 0)
library(glmmTMB)
Zag.1a <- glmmTMB(Biomass01 ~ Window.std + Fertilization +
Competition + Stress,
family = "binomial",
data = CTT2)
summary(Zag.1a)
#Step 2:
#And get the positive data
CTT2.pos <- subset(CTT2, Biomass > 0)
#And fit a Gamma GLMM
Zag.1b <- glmmTMB(Biomass ~ Window.std + Fertilization + Competition + Stress,
family = Gamma("log"),
data = CTT2.pos)
summary(Zag.1b)
#And the same model via glm:
Zag.1c <- glm(Biomass ~ Window.std + Fertilization +
Competition + Stress,
family = Gamma(link = "log"),
data = CTT2.pos)
summary(Zag.1c)
beta  <- coef(Zag.1c)
beta.glmmTMB <- fixef(Zag.1b)$cond
gamma <- fixef(Zag.1a)$cond
# Get the design matrices and the fitted values per component,
# and glue them together.
Xc <- model.matrix(~ Window.std + Fertilization + Competition + Stress,
data = CTT2.pos)
Xb <- model.matrix(~ Window.std + Fertilization + Competition + Stress,
data = CTT2)
#Calculate the two individual components of the model (mu and Pi)
eta.gamma  <- Xc %*% beta
eta.binary <- Xb %*% gamma
mu <- exp(eta.gamma)
P  <- exp(eta.binary) / (1 + exp(eta.binary))
#Blow up to the length of the data
mu.gamma <- rep(1, nrow(CTT2))
mu.gamma[CTT2$Biomass > 0] <- mu
# And calculate the ZAG (!!!!) expected values and variance:
r <- 1 / summary(Zag.1c)$dispersion
ExpY <- mu.gamma * P
VarY <- (P  * r + P - P^2 * r) * mu.gamma^2 * (1 / r)
# And calculate the Pearson residuals:
E.zag <- (CTT2$Biomass - ExpY) / sqrt(VarY)
#Plot fitted values versus residuals
plot(x = ExpY,
y = E.zag,
xlab = "Fitted values",
ylab = "Pearson residuals ZAG")
abline(h = 0, lty = 2)
#AIC of the ZAG model:
AIC(Zag.1a) + AIC(Zag.1c)
######################################################
#And some further model validation graphs
par(mfrow = c(2,2), mar = c(5,5,2,2), cex.lab = 1.5)
plot(x = ExpY,
y = E.zag,
xlab = "Expected values",
ylab = "Pearson residuals")
abline(h = 0, lty =2)
text(0.01, 7.5, "A", cex = 2)
plot(x = jitter(CTT2$Window),
y = E.zag,
xlab = "Window",
ylab = "Pearson residuals")
abline(h = 0, lty =2)
text(3.8, 7.5, "B", cex = 2)
plot(x = ExpY,
y = CTT2$Biomass,
xlab = "Expected values",
ylab = "Observed biomass",
xlim = c(0, 2.5),
ylim = c(0, 2.5)
)
text(0.01, 2.3, "C", cex = 2)
##########################################################
# Sketch the model fit
MyData <- expand.grid(Window.std = seq(-1.41, 1.41, length = 100),
Fertilization = levels(CTT2$Fertilization),
Competition = levels(CTT2$Competition),
Stress = levels(CTT2$Stress))
MyData$Window <- MyData$Window.std * sd(CTT2$Window) + mean(CTT2$Window)
X <- model.matrix(~ Window.std + Fertilization + Competition + Stress,
data = MyData)
mu   <- exp(X %*% beta)
Pi   <- exp(X %*% gamma) / (1 + exp(X %*% gamma))
ExpY <- Pi * mu
#Combine these three components with the MyData object
MyData2 <- cbind(MyData, mu, Pi, ExpY)
head(MyData2)
library(ggplot2)
p <- ggplot()
p <- p + geom_jitter(data = CTT2,
aes(y = Biomass, x = Window),
position = position_jitter(height = .01, width = 0.5))
p <- p + xlab("Window") + ylab("Biomass")
p <- p + theme(text = element_text(size=15))
p <- p + geom_line(data = MyData2,
aes(x = Window,
y = ExpY,
group = Competition,
colour = Competition,
fill = Competition))
p <- p + facet_grid(Fertilization ~ Stress, scales = "free_y")
p
MyData3  <- MyData2[MyData2$Competition == "0",]
p1 <- ggplot()
p1 <- p1 + geom_jitter(data = CTT2,
aes(y = Biomass, x = Window),
position = position_jitter(height = .01, width = 0.5))
p1 <- p1 + xlab("Window") + ylab("Expected biomass values")
p1 <- p1 + theme(text = element_text(size=15))
# Expected ZAG values
p1 <- p1 + geom_line(data = MyData3,
aes(x = Window,
y = ExpY),
size = 2,
col = 1)
p1 <- p1 + facet_grid(Fertilization ~ Stress, scales = "free_y")
p1
quartz()  #Mac command for a new window. Use win.graph() on a Windows computer
p2 <- ggplot()
p2 <- p2 + geom_jitter(data = CTT2,
aes(y = Biomass, x = Window),
position = position_jitter(height = .01, width = 0.5))
p2 <- p2 + xlab("Window") + ylab("Expected mean Gamma part")
p2 <- p2 + theme(text = element_text(size=15))
#mu component
p2 <- p2 + geom_line(data = MyData3,
aes(x = Window,
y = mu),
col = 3)
p2 <- p2 + facet_grid(Fertilization ~ Stress, scales = "free_y")
p2
quartz()  #Mac command for a new window. Use win.graph() on a Windows computer
#Probability of presence
p3 <- ggplot()
p3 <- p3 + geom_jitter(data = CTT2,
aes(y = Biomass.01, x = Window),
position = position_jitter(height = .01, width = 0.5))
p3 <- p3 + xlab("Window") + ylab("Probability of presence")
p3 <- p3 + theme(text = element_text(size=15))
#Pi components
p3 <- p3 + geom_line(data = MyData3,
aes(x = Window,
y = Pi),
linetype = 2,
col = 2)
setwd("~/GitHub/IODS-project/data")
#read in the csv
alc<-read.csv("C:/Users/Sirke Piirainen/Documents/GitHub/IODS-project/data/alc.csv",header = T)
#print the names of the columns
names(alc)
```{r}
#get some packages
library(tidyr); library(dplyr); library(ggplot2)
#select only the data that I am interested in
choose<-c("high_use","famrel","absences","studytime","higher")
alc2<-select(alc,one_of(choose))
#summary table of the data
summary(alc2)
#draw barplots of variables to study their distribution
gather(alc2) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free")+geom_bar()
library(GGally)
library(ggplot2)
# create a plot matrix with ggpairs()
p <- ggpairs(alc2, mapping = aes(col=high_use,alpha=0.3), lower = list(combo = wrap("facethist", bins = 20)))
# draw the plot
p
library(GGally)
library(ggplot2)
# create a plot matrix with ggpairs()
p <- ggpairs(alc2, mapping = aes(col=high_use,alpha=0.3), lower = list(combo = wrap("facethist", bins = 20)))
# draw the plot
p
#fit a logistic regression model
m <- glm(high_use ~ famrel + absences+studytime+higher-1, data = alc2, family = "binomial")
#plot a summary table
summary(m)
my.mod1 <- glm(high_use ~ famrel + absences+studytime+higher-1, data = alc2, family = "binomial") # with rank
my.mod2 <- glm(high_use ~ famrel + absences+studytime-1, data = alc2, family = "binomial") # without rank
anova(my.mod1, my.mod2, test="LRT")
#the new model again
m2 <- glm(high_use ~ famrel + absences+studytime, data = alc2, family = "binomial")
#summary table of the new model
summary(m2)
m3<-glm(formula = high_use ~ absences + studytime, family = "binomial",
data = alc2)
summary(m3)
OR <- coef(m3) %>% exp
# compute confidence intervals (CI)
CI<-confint(m3)%>%exp
# print out the odds ratios with their confidence intervals
cbind(OR, CI)
# predict() the probability of high_use
probabilities <- predict(m3, type = "response")
# add the predicted probabilities to 'alc'
alc2 <- mutate(alc2, probability = probabilities)
View(alc2)
# use the probabilities to make a prediction of high_use
alc2 <- mutate(alc2, prediction = probability>0.5)
# see the last ten original classes, predicted probabilities, and class predictions
select(alc2, studytime, absences, high_use, probability, prediction) %>% tail(10)
# tabulate the target variable versus the predictions
table(high_use = alc2$high_use, prediction = alc2$prediction)
# tabulate the target variable versus the predictions
table(high_use = alc2$high_use, prediction = alc2$prediction)%>%prop.table()%>%addmargins()
g <- ggplot(alc2, aes(x = probability, y = high_use,col=prediction))
# define the geom as points and draw the plot
g+geom_point()
# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
n_wrong <- abs(class - prob) > 0.5
mean(n_wrong)
}
# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc2$high_use, prob = alc2$probability)
# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc2, cost = loss_func, glmfit = m, K = 10)
# average number of wrong predictions in the cross validation
cv$delta[1]
cv <- cv.glm(data = alc2, cost = loss_func, glmfit = m, K = 10)
# average number of wrong predictions in the cross validation
cv$delta[1]
cv <- cv.glm(data = alc2, cost = loss_func, glmfit = m, K = 10)
# average number of wrong predictions in the cross validation
cv$delta[1]
cv <- cv.glm(data = alc2, cost = loss_func, glmfit = m, K = 10)
# average number of wrong predictions in the cross validation
cv$delta[1]
